I am a PhD student in Computer Science at Viriginia Tech.

I am interested in exploring the domain of video prediction in artificial intelligence context. Simply put video prediction is the task of predicting the next set of frame(s) of a given video. If a video contains an action being performed by a robot, the task is of predicting the next immediate action after the current action. The next immediate action might also be just completing the current action[1] or might be a next logical action after the current action. Wide availability of videos on the web provides a lucrative opportunity for artificial intelligence researchers to leverage them for building models that can be trained for useful AI tasks like the ones mentioned above. Predicting future frames can help autonomous agents perform their tasks better. For e.g. if a self-driving car that takes in a continous feed of images from its surroundings can predict events like accidents before they actually happen based on the inferred motion of the objects in its surroundings they might take action to prevent such events and avoid a mishap from happening. Since consecutive frames of videos are highly correlated videos naturally provide self supervision alleviating the need for human supervision and labeled data and a rich opportunity to develop methods for unsupervised learning. 

This is a space where I will be writing notes on my readings pertaining to this topic and any interesting ideas that come to my mind. 














References:
Unsupervised learning through physical interaction for video prediction.